# spark master
mist.spark.master = "local[*]"

mist.hive.test = true

mist.settings.thread-number = 16

mist.http.on = true
mist.http.host = "0.0.0.0"
mist.http.port = 2003

mist.mqtt.on = true
mist.mqtt.host = "mosquitto"
mist.mqtt.port = 1883
mist.mqtt.subscribe-topic = "foo"
mist.mqtt.publish-topic = "foo"

# mist.workers.run = "local"
mist.workers.run = "docker" # it works with swarm
mist.workers.host = "172.17.0.1"
mist.workers.port = 2375

mist.recovery.on = true
mist.recovery.multilimit = 10
mist.recovery.typedb = "MapDb"
mist.recovery.dbfilename = "file.db"

mist.contexts.foo.timeout = 100 days

mist.context-defaults.disposable = false

mist.contexts.foo.spark-conf = {
  spark.default.parallelism = 4
  spark.driver.memory = "128m"
  spark.executor.memory = "64m"
  spark.scheduler.mode = "FAIR"
}

mist.contexts.testtimeout.timeout = 1 nanoseconds
mist.akka {
  remote {
    log-remote-lifecycle-events = off
    log-recieved-messages = off
    netty.tcp {
      hostname = "0.0.0.0"
    }
    transport-failure-detector {
      heartbeat-interval = 30s
      acceptable-heartbeat-pause = 5s
    }
  }
  # Event handlers to register at boot time (Logging$DefaultLogger logs to STDOUT)
  loggers = ["akka.event.Logging$DefaultLogger"]
  cluster {
    seed-nodes = ["akka.tcp://mist@master:2551"]
    auto-down-unreachable-after = 10s
  }
}
